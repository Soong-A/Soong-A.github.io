<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>DenseNet论文学习笔 | Soong's blog</title><meta name="author" content="Soong"><meta name="copyright" content="Soong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="DenseNet 深度解析笔记📌 核心思想与设计哲学1. 三种网络结构对比python 12345678# 传统网络：信息逐层替换x_l &#x3D; H_l(x_&#123;l-1&#125;)# ResNet：信息加法融合  x_l &#x3D; H_l(x_&#123;l-1&#125;) + x_&#123;l-1&#125;  # 逐元素相加，信息混合# DenseNet：信息拼接累积x_l &#x3D; H_l(">
<meta property="og:type" content="article">
<meta property="og:title" content="DenseNet论文学习笔">
<meta property="og:url" content="https://soong-a.github.io/2025/11/26/DenseNet/index.html">
<meta property="og:site_name" content="Soong&#39;s blog">
<meta property="og:description" content="DenseNet 深度解析笔记📌 核心思想与设计哲学1. 三种网络结构对比python 12345678# 传统网络：信息逐层替换x_l &#x3D; H_l(x_&#123;l-1&#125;)# ResNet：信息加法融合  x_l &#x3D; H_l(x_&#123;l-1&#125;) + x_&#123;l-1&#125;  # 逐元素相加，信息混合# DenseNet：信息拼接累积x_l &#x3D; H_l(">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://soong-a.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2025-11-26T13:18:00.000Z">
<meta property="article:modified_time" content="2025-11-26T11:30:27.428Z">
<meta property="article:author" content="Soong">
<meta property="article:tag" content="图像处理">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="基础知识">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://soong-a.github.io/img/avatar.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DenseNet论文学习笔",
  "url": "https://soong-a.github.io/2025/11/26/DenseNet/",
  "image": "https://soong-a.github.io/img/avatar.jpg",
  "datePublished": "2025-11-26T13:18:00.000Z",
  "dateModified": "2025-11-26T11:30:27.428Z",
  "author": [
    {
      "@type": "Person",
      "name": "Soong",
      "url": "https://soong-a.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://soong-a.github.io/2025/11/26/DenseNet/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DenseNet论文学习笔',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/index.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Soong's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">DenseNet论文学习笔</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">DenseNet论文学习笔</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-11-26T13:18:00.000Z" title="发表于 2025-11-26 21:18:00">2025-11-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-11-26T11:30:27.428Z" title="更新于 2025-11-26 19:30:27">2025-11-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90/">医学图像分析</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90/Densely-Connected-Convolutional-Networks/">Densely Connected Convolutional Networks</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h1 id="DenseNet-深度解析笔记"><a href="#DenseNet-深度解析笔记" class="headerlink" title="DenseNet 深度解析笔记"></a>DenseNet 深度解析笔记</h1><h2 id="📌-核心思想与设计哲学"><a href="#📌-核心思想与设计哲学" class="headerlink" title="📌 核心思想与设计哲学"></a>📌 核心思想与设计哲学</h2><h3 id="1-三种网络结构对比"><a href="#1-三种网络结构对比" class="headerlink" title="1. 三种网络结构对比"></a>1. 三种网络结构对比</h3><p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 传统网络：信息逐层替换</span><br><span class="line">x_l = H_l(x_&#123;l-1&#125;)</span><br><span class="line"></span><br><span class="line"># ResNet：信息加法融合  </span><br><span class="line">x_l = H_l(x_&#123;l-1&#125;) + x_&#123;l-1&#125;  # 逐元素相加，信息混合</span><br><span class="line"></span><br><span class="line"># DenseNet：信息拼接累积</span><br><span class="line">x_l = H_l([x_0, x_1, ..., x_&#123;l-1&#125;])  # 通道维度拼接，信息并列</span><br></pre></td></tr></table></figure>



<h3 id="2-信息流本质区别"><a href="#2-信息流本质区别" class="headerlink" title="2. 信息流本质区别"></a>2. 信息流本质区别</h3><p><strong>ResNet（接力赛跑模式）</strong>：</p>
<p>text</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A → B → C</span><br><span class="line">每个运动员跑完就离开，只有当前运动员在场上</span><br></pre></td></tr></table></figure>



<p><strong>DenseNet（团队头脑风暴模式）</strong>：</p>
<p>text</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A → [A+B] → [A+B+C]</span><br><span class="line">所有专家持续在场，共同贡献智慧</span><br></pre></td></tr></table></figure>



<h2 id="🏗️-架构详解"><a href="#🏗️-架构详解" class="headerlink" title="🏗️ 架构详解"></a>🏗️ 架构详解</h2><h3 id="1-完整的DenseNet数据流"><a href="#1-完整的DenseNet数据流" class="headerlink" title="1. 完整的DenseNet数据流"></a>1. 完整的DenseNet数据流</h3><p>text</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">输入图片 → 初始卷积 → Dense Block 1 → Transition 1 → Dense Block 2 → Transition 2 → ...</span><br></pre></td></tr></table></figure>



<p><strong>具体尺寸变化示例</strong>：</p>
<p>text</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">输入: 224×224×3</span><br><span class="line">初始卷积: 112×112×64</span><br><span class="line">Dense Block 1: 所有层保持112×112尺寸，通道数增长</span><br><span class="line">Transition 1: 56×56×128 (通道压缩+尺寸减半)</span><br><span class="line">Dense Block 2: 所有层保持56×56尺寸，通道数重新开始增长</span><br></pre></td></tr></table></figure>



<h3 id="2-Dense-Block内部工作机制"><a href="#2-Dense-Block内部工作机制" class="headerlink" title="2. Dense Block内部工作机制"></a>2. Dense Block内部工作机制</h3><p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 详细的前向传播过程</span><br><span class="line">def dense_block_forward(x, growth_rate=32, num_layers=6):</span><br><span class="line">    features = [x]  # 存储所有已计算的特征图</span><br><span class="line">    </span><br><span class="line">    for l in range(num_layers):</span><br><span class="line">        # 当前输入是前面所有层输出的拼接</span><br><span class="line">        current_input = torch.cat(features, dim=1)  # [x_0, x_1, ..., x_&#123;l-1&#125;]</span><br><span class="line">        </span><br><span class="line">        # 产生新特征（包含Bottleneck）</span><br><span class="line">        new_features = H_l(current_input)  # 输出growth_rate个新通道</span><br><span class="line">        </span><br><span class="line">        # 将新特征加入集合</span><br><span class="line">        features.append(new_features)</span><br><span class="line">    </span><br><span class="line">    return torch.cat(features, dim=1)</span><br></pre></td></tr></table></figure>



<h3 id="3-通道增长的具体数学"><a href="#3-通道增长的具体数学" class="headerlink" title="3. 通道增长的具体数学"></a>3. 通道增长的具体数学</h3><p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 假设 growth_rate = 32, 初始通道 = 64</span><br><span class="line">第1层输入: 64通道 → 输出: 32新通道 → 总通道: 96</span><br><span class="line">第2层输入: 96通道 → 输出: 32新通道 → 总通道: 128  </span><br><span class="line">第3层输入: 128通道 → 输出: 32新通道 → 总通道: 160</span><br><span class="line">第4层输入: 160通道 → 输出: 32新通道 → 总通道: 192</span><br><span class="line">第5层输入: 192通道 → 输出: 32新通道 → 总通道: 224</span><br><span class="line">第6层输入: 224通道 → 输出: 32新通道 → 总通道: 256</span><br><span class="line"></span><br><span class="line"># 通用公式：第l层总通道数 = 初始通道 + growth_rate × l</span><br></pre></td></tr></table></figure>



<h2 id="🔑-关键技术细节"><a href="#🔑-关键技术细节" class="headerlink" title="🔑 关键技术细节"></a>🔑 关键技术细节</h2><h3 id="1-Bottleneck-Layer的精确作用"><a href="#1-Bottleneck-Layer的精确作用" class="headerlink" title="1. Bottleneck Layer的精确作用"></a>1. Bottleneck Layer的精确作用</h3><p><strong>位置</strong>：在Dense Block内部，每个3x3卷积之前<br><strong>目的</strong>：临时压缩通道数，优化计算效率</p>
<p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 计算复杂度对比（假设第6层，输入224通道，growth_rate=32）</span><br><span class="line"></span><br><span class="line"># 没有Bottleneck：</span><br><span class="line">3x3卷积计算量 = 224 × 32 × 3 × 3 = 64,512次乘加</span><br><span class="line"></span><br><span class="line"># 有Bottleneck：</span><br><span class="line">1x1卷积计算量 = 224 × 128 × 1 × 1 = 28,672次乘加</span><br><span class="line">3x3卷积计算量 = 128 × 32 × 3 × 3 = 36,864次乘加  </span><br><span class="line">总计算量 = 65,536次乘加</span><br><span class="line"></span><br><span class="line"># 虽然总计算量相近，但3x3卷积的计算量大为减少，内存访问模式更优</span><br></pre></td></tr></table></figure>



<h3 id="2-Transition-Layer-vs-Bottleneck"><a href="#2-Transition-Layer-vs-Bottleneck" class="headerlink" title="2. Transition Layer vs Bottleneck"></a>2. Transition Layer vs Bottleneck</h3><table>
<thead>
<tr>
<th align="left">组件</th>
<th align="left">位置</th>
<th align="left">主要作用</th>
<th align="left">是否改变尺寸</th>
<th align="left">是否永久改变通道</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>Bottleneck</strong></td>
<td align="left">Dense Block内部</td>
<td align="left">临时压缩通道，优化3x3卷积计算</td>
<td align="left">❌ 不变</td>
<td align="left">❌ 临时压缩</td>
</tr>
<tr>
<td align="left"><strong>Transition</strong></td>
<td align="left">Dense Block之间</td>
<td align="left">永久压缩通道，控制模型增长</td>
<td align="left">✅ 尺寸减半</td>
<td align="left">✅ 永久压缩</td>
</tr>
</tbody></table>
<h3 id="3-拼接-concat-vs-加法-add-的本质区别"><a href="#3-拼接-concat-vs-加法-add-的本质区别" class="headerlink" title="3. 拼接(concat) vs 加法(add)的本质区别"></a>3. 拼接(concat) vs 加法(add)的本质区别</h3><p><strong>加法（ResNet）</strong>：</p>
<p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 数值混合，信息不可分离</span><br><span class="line">特征图A: [[1,2], [3,4]] + 特征图B: [[5,6], [7,8]] = 结果: [[6,8], [10,12]]</span><br><span class="line"># 像混合颜料，无法再分离原始颜色</span><br></pre></td></tr></table></figure>



<p><strong>拼接（DenseNet）</strong>：</p>
<p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 信息并列保存，保持独立性</span><br><span class="line">特征图A(2通道) + 特征图B(2通道) = 结果(4通道)</span><br><span class="line"># 像调色板排列颜料，每种颜色保持独立可用</span><br></pre></td></tr></table></figure>



<h2 id="🎯-在医学影像中的特殊价值"><a href="#🎯-在医学影像中的特殊价值" class="headerlink" title="🎯 在医学影像中的特殊价值"></a>🎯 在医学影像中的特殊价值</h2><h3 id="1-特征复用优势"><a href="#1-特征复用优势" class="headerlink" title="1. 特征复用优势"></a>1. 特征复用优势</h3><ul>
<li><strong>多尺度特征同时可用</strong>：低级边缘特征 + 中级形状特征 + 高级语义特征</li>
<li><strong>避免信息丢失</strong>：原始特征始终可用，不会在深度传递中被”遗忘”</li>
<li><strong>梯度流动优化</strong>：浅层直接连接到深层，缓解梯度消失</li>
</ul>
<h3 id="2-针对医学图像的特性适配"><a href="#2-针对医学图像的特性适配" class="headerlink" title="2. 针对医学图像的特性适配"></a>2. 针对医学图像的特性适配</h3><p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 医学图像特点与DenseNet优势对应</span><br><span class="line">medical_advantages = &#123;</span><br><span class="line">    &#x27;小样本学习&#x27;: &#x27;高参数效率，每层只学少量新特征&#x27;,</span><br><span class="line">    &#x27;多尺度病变&#x27;: &#x27;所有层次特征可直接复用&#x27;, </span><br><span class="line">    &#x27;细微结构&#x27;: &#x27;原始细节特征不会在深度传递中丢失&#x27;,</span><br><span class="line">    &#x27;复杂纹理&#x27;: &#x27;多尺度特征组合能力强大&#x27;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="3-实际配置建议"><a href="#3-实际配置建议" class="headerlink" title="3. 实际配置建议"></a>3. 实际配置建议</h3><p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 标准医学影像配置</span><br><span class="line">densenet_medical = &#123;</span><br><span class="line">    &#x27;growth_rate&#x27;: 32,           # 平衡性能与效率</span><br><span class="line">    &#x27;block_config&#x27;: [6, 12, 24, 16],  # 渐进加深</span><br><span class="line">    &#x27;compression&#x27;: 0.5,          # 控制通道增长</span><br><span class="line">    &#x27;bottleneck_ratio&#x27;: 4,       # 1x1卷积输出4*k通道</span><br><span class="line">    &#x27;num_init_features&#x27;: 64      # 初始通道数</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 轻量级医学配置（移动端/小数据集）</span><br><span class="line">densenet_light = &#123;</span><br><span class="line">    &#x27;growth_rate&#x27;: 12,           # 更小的增长率</span><br><span class="line">    &#x27;block_config&#x27;: [4, 8, 12, 8],    # 更少的层数</span><br><span class="line">    &#x27;compression&#x27;: 0.5,</span><br><span class="line">    &#x27;bottleneck_ratio&#x27;: 4,</span><br><span class="line">    &#x27;num_init_features&#x27;: 48</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="⚡-训练与优化技巧"><a href="#⚡-训练与优化技巧" class="headerlink" title="⚡ 训练与优化技巧"></a>⚡ 训练与优化技巧</h2><h3 id="1-内存优化策略"><a href="#1-内存优化策略" class="headerlink" title="1. 内存优化策略"></a>1. 内存优化策略</h3><p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># DenseNet的内存挑战与解决方案</span><br><span class="line">memory_solutions = &#123;</span><br><span class="line">    &#x27;梯度检查点&#x27;: &#x27;牺牲计算时间换取内存空间&#x27;,</span><br><span class="line">    &#x27;调整batch_size&#x27;: &#x27;找到内存与性能的平衡点&#x27;, </span><br><span class="line">    &#x27;混合精度训练&#x27;: &#x27;使用FP16减少内存占用&#x27;,</span><br><span class="line">    &#x27;数据加载优化&#x27;: &#x27;预加载和流水线处理&#x27;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="2-医学数据特殊处理"><a href="#2-医学数据特殊处理" class="headerlink" title="2. 医学数据特殊处理"></a>2. 医学数据特殊处理</h3><p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def adapt_densenet_for_medical(model, medical_config):</span><br><span class="line">    # 修改输入通道适应医学图像（如1通道CT或多模态）</span><br><span class="line">    model.features[0] = nn.Conv2d(</span><br><span class="line">        medical_config[&#x27;in_channels&#x27;],  # 可能是1, 3, 或更多</span><br><span class="line">        model.num_init_features,</span><br><span class="line">        kernel_size=7, stride=2, padding=3, bias=False</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    # 调整分类头适应医学任务</span><br><span class="line">    model.classifier = nn.Linear(</span><br><span class="line">        model.classifier.in_features,</span><br><span class="line">        medical_config[&#x27;num_classes&#x27;]  # 疾病分类数</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    return model</span><br></pre></td></tr></table></figure>



<h2 id="🔄-与其他模型的对比理解"><a href="#🔄-与其他模型的对比理解" class="headerlink" title="🔄 与其他模型的对比理解"></a>🔄 与其他模型的对比理解</h2><h3 id="1-信息保留能力对比"><a href="#1-信息保留能力对比" class="headerlink" title="1. 信息保留能力对比"></a>1. 信息保留能力对比</h3><table>
<thead>
<tr>
<th align="left">模型</th>
<th align="left">信息流模式</th>
<th align="left">特征保留</th>
<th align="left">梯度流动</th>
<th align="left">参数效率</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>传统CNN</strong></td>
<td align="left">替换式</td>
<td align="left">差</td>
<td align="left">容易消失</td>
<td align="left">中等</td>
</tr>
<tr>
<td align="left"><strong>ResNet</strong></td>
<td align="left">加法融合</td>
<td align="left">中等</td>
<td align="left">较好</td>
<td align="left">较好</td>
</tr>
<tr>
<td align="left"><strong>DenseNet</strong></td>
<td align="left">拼接累积</td>
<td align="left">优秀</td>
<td align="left">优秀</td>
<td align="left">优秀</td>
</tr>
</tbody></table>
<h3 id="2-在医学影像任务中的选择指南"><a href="#2-在医学影像任务中的选择指南" class="headerlink" title="2. 在医学影像任务中的选择指南"></a>2. 在医学影像任务中的选择指南</h3><p>python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def model_selection_guide(medical_task):</span><br><span class="line">    guide = &#123;</span><br><span class="line">        &#x27;分割任务&#x27;: &#x27;U-Net (DenseNet作为编码器)&#x27;,</span><br><span class="line">        &#x27;分类任务&#x27;: &#x27;DenseNet-121/169&#x27;,</span><br><span class="line">        &#x27;检测任务&#x27;: &#x27;DenseNet + Detection Head&#x27;, </span><br><span class="line">        &#x27;小样本学习&#x27;: &#x27;DenseNet-BC (轻量版)&#x27;,</span><br><span class="line">        &#x27;3D体积数据&#x27;: &#x27;3D DenseNet&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">    return guide.get(medical_task, &#x27;DenseNet-121&#x27;)</span><br></pre></td></tr></table></figure>



<h2 id="💡-关键洞察总结"><a href="#💡-关键洞察总结" class="headerlink" title="💡 关键洞察总结"></a>💡 关键洞察总结</h2><h3 id="1-核心创新点"><a href="#1-核心创新点" class="headerlink" title="1. 核心创新点"></a>1. 核心创新点</h3><ul>
<li><strong>密集连接</strong>：不是重复计算，而是智能的特征复用</li>
<li><strong>拼接操作</strong>：保持特征独立性，优于加法融合</li>
<li><strong>Growth Rate</strong>：人为控制的”节流阀”，精确控制模型复杂度</li>
<li><strong>模块化设计</strong>：Bottleneck优化计算，Transition控制增长</li>
</ul>
<h3 id="2-在医学影像中的独特价值"><a href="#2-在医学影像中的独特价值" class="headerlink" title="2. 在医学影像中的独特价值"></a>2. 在医学影像中的独特价值</h3><ul>
<li><strong>特征永不丢失</strong>：原始医学特征始终可用，适合细微结构分析</li>
<li><strong>多尺度智能组合</strong>：自动综合利用不同抽象层次的特征</li>
<li><strong>高参数效率</strong>：在数据有限的医学任务中尤为重要</li>
</ul>
<h3 id="3-实用要点"><a href="#3-实用要点" class="headerlink" title="3. 实用要点"></a>3. 实用要点</h3><ul>
<li><strong>Bottleneck在Block内</strong>，<strong>Transition在Block间</strong></li>
<li><strong>每个Dense Block独立累积</strong>通道数，Transition负责重置</li>
<li><strong>拼接保留所有信息</strong>，加法会混合信息</li>
<li><strong>Growth Rate是人为超参数</strong>，完全可控设计</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://soong-a.github.io">Soong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://soong-a.github.io/2025/11/26/DenseNet/">https://soong-a.github.io/2025/11/26/DenseNet/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://soong-a.github.io" target="_blank">Soong's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/11/27/SENet/" title="Squeeze-and-Excitation Networks (SENet)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Squeeze-and-Excitation Networks (SENet)</div></div><div class="info-2"><div class="info-item-1">Squeeze-and-Excitation Networks (SENet)论文信息 论文标题: Squeeze-and-Excitation Networks 论文链接: https://arxiv.org/abs/1709.01507 官方代码: GitHub - hujie-frank&#x2F;SENet PyTorch实现: GitHub - miraclewkf&#x2F;SENet-PyTorch  一、SENet概述竞赛成绩SENet在ImageNet 2017竞赛图像分类任务中夺冠，取得突破性成果：  原最佳成绩: 2.991% (top-5 error) SENet成绩: 2.251% (top-5 error) 提升幅度: 0.74% 绝对提升  核心思想 研究动机: 显式建模特征通道间的相互依赖关系 技术策略: 采用”特征重标定”策略，避免引入新的空间维度 工作机制: 通过网络学习自动获取每个特征通道的重要程度 实现方式: 提升有用特征通道权重，抑制次要特征通道权重  架构特点 模块化设计: SE block作为子结构，可嵌入现有网络 端到端训练: 完全...</div></div></div></a><a class="pagination-related" href="/2025/11/19/%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/" title="模型学习分类"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">模型学习分类</div></div><div class="info-2"><div class="info-item-1">一、 基础与骨干网络（构建模型的基本单元）这些是构成复杂模型的基石，如同建筑的砖瓦。    模型 核心思想 在医学图像中的作用    CNN 使用卷积核提取局部特征，通过池化层降维。 所有医学图像分析的起点。用于提取图像中的基础特征，如边缘、纹理。   VGG 通过堆叠小的卷积核来增加网络深度。 结构简单，常作为U-Net等分割模型的编码器（主干网络）。   ResNet 引入“残差连接”，解决深层网络梯度消失问题，让网络可以做得非常深。 医学图像中最常用的主干网络。强大的特征提取能力，用于分类、分割和检测。   DenseNet 每一层都与前面所有层相连，特征复用率极高。 作为主干网络，在数据量较小的医学任务中能更高效地利用特征。   EfficientNet 复合缩放网络深度、宽度和分辨率，在计算量和准确率间取得最佳平衡。 适合资源受限（如你的笔记本）的场景，是轻量且高效的主干网络选择。   Vision Transformer 将图像切块，用Transformer的自注意力机制捕捉全局依赖关系。 解决CNN感受野有限的问题，特别适合需要全局信息的任务，如分类、大器官分割。 ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/12/3D%20Res2Net%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--3D Res2Net的改造和使用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-12</div><div class="info-item-2">MM-UNet 论文学习笔记--3D Res2Net的改造和使用</div></div><div class="info-2"><div class="info-item-1">编码器细节：3D Res2Net的改造和使用核心思想我们选用了一个叫Res2Net的”高手”来做编码器，但它本来是处理2D普通照片的。我们通过一些巧妙的”改造”，让它能处理我们的3D医学图像，并且还让它继承了之前在普通照片上学到的”经验”。 为什么选择Res2Net？Res2Net的每个残差块内部都有分层式的残差连接，这让它能更有效地在粒度级别使用多尺度信息，扩展每一层的感受野。 就像工人同时拿着多种不同倍数的放大镜在工作：  一个小放大镜看细微的纹理和边缘（小尺度特征） 一个中倍放大镜看局部的结构（中尺度特征） 一个大倍放大镜看大致的轮廓（大尺度特征）  这对于边界模糊的前列腺图像来说，非常有用。 编码器的具体工作流程第一步：初始卷积（Convolution Stem）给定的图像首先通过一个卷积茎，它由并行的3×3×3卷积和1×1×1卷积组成，后面跟着求和操作。  3×3×3卷积：捕捉图像中小范围的、基本的局部特征（比如某个点是不是边缘） 1×1×1卷积：主要负责调整数据的通道数，为后续处理做准备 最后把两个结果相加，得到一个包含丰富基础信息的特征图  第二步：核心特征提取然后...</div></div></div></a><a class="pagination-related" href="/2025/11/12/AFFM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-12</div><div class="info-item-2">MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)</div></div><div class="info-2"><div class="info-item-1">AFFM (自适应特征融合模块) 学习笔记 🎯 解决的问题传统方法的缺陷：  直接将高层特征（轮廓信息）与低层特征（细节信息）拼接 导致背景噪声混入有用信息中 影响最终分割的精准度  🏗️ 模块设计思路AFFM就像一个智能的制图师，能够智能地融合两种不同类型的地图：  低层特征 &#x3D; “细节地图” ✅ 优点：包含丰富的边缘、纹理等细节信息 ❌ 缺点：混杂大量背景噪声，缺乏整体概念   高层特征 &#x3D; “轮廓地图” ✅ 优点：包含前列腺整体形状的语义信息 ❌ 缺点：缺乏精确定位的细节    🔄 三步骤工作流程第一步：特征对齐与拼接&#x2F;img&#x2F;屏幕截图 2025-11-12 215920.png 临时特征 &#x3D; 拼接(上采样(高层特征), 低层特征)  动作：将高层特征上采样到与低层特征相同尺寸 目的：让两种特征可以在同一尺度上进行融合  第二步：智能权重计算（核心创新）&#x2F;img&#x2F;屏幕截图 2025-11-12 220019.png 重要性权重 &#x3D; Sigmoid(全连接层2(全连接层1(全局平均池化(临时...</div></div></div></a><a class="pagination-related" href="/2025/11/12/A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images%20%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="MM-UNet 论文学习笔记--AFFM GCM MACM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-12</div><div class="info-item-2">MM-UNet 论文学习笔记--AFFM GCM MACM</div></div><div class="info-2"><div class="info-item-1">MM-UNet：3D前列腺MR图像分割方法核心目标：为什么要做这个研究？医生有一张前列腺的3D核磁共振（MR）图像，他们需要精确地知道图像中哪些像素是属于前列腺的。这个过程叫做”分割”。 手动分割的问题：非常耗时、费力，而且不同医生的判断可能会有差异。 自动分割的挑战：计算机来做这件事，面临三个主要难题：  图像质量差：MR图像背景杂乱（噪声多），前列腺边界模糊。 关系复杂：前列腺的形状和它周围的组织（膀胱、直肠等）是相互关联的，计算机需要理解整个图像的”上下文”才能准确判断边界。 数据特殊：3D的MR图像在上下、左右、前后三个方向的分辨率（清晰度）是不一样的。这导致传统的3D处理方法效果不好。  MM-UNET就是为了解决这三个挑战而设计的。 创新点一：自适应特征融合模块 (AFFM) – 解决”如何精准融合信息”1. 为什么需要它？在分割网络中，存在两种信息：  低级特征：来自网络的浅层，包含丰富的细节信息（如边缘、纹理），但也混有很多背景噪声。 高级特征：来自网络的深层，包含抽象的语义信息（知道”这是前列腺”），但缺乏细节，比较粗糙。  传统方法简单地把这两种特征拼接在一起...</div></div></div></a><a class="pagination-related" href="/2025/11/27/SENet/" title="Squeeze-and-Excitation Networks (SENet)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-27</div><div class="info-item-2">Squeeze-and-Excitation Networks (SENet)</div></div><div class="info-2"><div class="info-item-1">Squeeze-and-Excitation Networks (SENet)论文信息 论文标题: Squeeze-and-Excitation Networks 论文链接: https://arxiv.org/abs/1709.01507 官方代码: GitHub - hujie-frank&#x2F;SENet PyTorch实现: GitHub - miraclewkf&#x2F;SENet-PyTorch  一、SENet概述竞赛成绩SENet在ImageNet 2017竞赛图像分类任务中夺冠，取得突破性成果：  原最佳成绩: 2.991% (top-5 error) SENet成绩: 2.251% (top-5 error) 提升幅度: 0.74% 绝对提升  核心思想 研究动机: 显式建模特征通道间的相互依赖关系 技术策略: 采用”特征重标定”策略，避免引入新的空间维度 工作机制: 通过网络学习自动获取每个特征通道的重要程度 实现方式: 提升有用特征通道权重，抑制次要特征通道权重  架构特点 模块化设计: SE block作为子结构，可嵌入现有网络 端到端训练: 完全...</div></div></div></a><a class="pagination-related" href="/2025/11/13/MACM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--MACM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-13</div><div class="info-item-2">MM-UNet 论文学习笔记--MACM</div></div><div class="info-2"><div class="info-item-1">Multi-scale Anisotropic Convolution Module (MACM) 技术笔记模块概述核心目标MACM旨在解决3D医学图像分割中的三个关键挑战：  各向异性分辨率：适应不同方向的空间分辨率差异 多尺度特征需求：同时捕获局部细节和全局上下文 计算效率：在保持性能的同时控制计算复杂度  技术定位MACM是专门为3D医学图像设计的特征提取模块，通常集成在编码器路径中，用于增强特征的判别能力和空间感知。 整体架构模块组成graph TD     A[输入特征] --&gt; B[1×1×1卷积&lt;br&gt;通道调整]     B --&gt; C[并行ACB处理]          C --&gt; D[ACB k=3]     C --&gt; E[ACB k=7]      C --&gt; F[ACB k=13]     C --&gt; G[ACB k=15]          D --&gt; H[特征拼接]     E --&gt; H     F --&gt; H     G --&gt; H          H --&gt; I[残差...</div></div></div></a><a class="pagination-related" href="/2025/11/13/GCM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--GCM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-13</div><div class="info-item-2">MM-UNet 论文学习笔记--GCM</div></div><div class="info-2"><div class="info-item-1">Global Context-aware Module (GCM)概述GCM是一个用于医学图像分割的全局上下文理解模块，通过结合CNN的局部特征提取能力和Mamba的长序列建模能力，实现高效的全局上下文捕获。 1. GCM整体架构flowchart TD     A[输入特征图&lt;br&gt;B×C×H×W×D] --&gt; B[残差块1&lt;br&gt;Conv+IN+LeakyReLU]     B --&gt; C[残差块2&lt;br&gt;Conv+IN+LeakyReLU]     C --&gt; D[重塑序列&lt;br&gt;B×L×C&lt;br&gt;L=H×W×D]     D --&gt; E[Layer Normalization]     E --&gt; F[Mamba块]     F --&gt; G[重塑回空间结构&lt;br&gt;B×C×H×W×D]     G --&gt; H[输出特征图]          class A,B,C,D,E,F,G,H normal;          classDef normal fill:n...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Soong</div><div class="author-info-description">有关机器学习，力扣代码训练等，欢迎探索</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Soong-A" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:926315593@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#DenseNet-%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">DenseNet 深度解析笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%93%B2%E5%AD%A6"><span class="toc-number">1.1.</span> <span class="toc-text">📌 核心思想与设计哲学</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%B8%89%E7%A7%8D%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%AF%B9%E6%AF%94"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. 三种网络结构对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BF%A1%E6%81%AF%E6%B5%81%E6%9C%AC%E8%B4%A8%E5%8C%BA%E5%88%AB"><span class="toc-number">1.1.2.</span> <span class="toc-text">2. 信息流本质区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8F%97%EF%B8%8F-%E6%9E%B6%E6%9E%84%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.2.</span> <span class="toc-text">🏗️ 架构详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%8C%E6%95%B4%E7%9A%84DenseNet%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="toc-number">1.2.1.</span> <span class="toc-text">1. 完整的DenseNet数据流</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Dense-Block%E5%86%85%E9%83%A8%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">1.2.2.</span> <span class="toc-text">2. Dense Block内部工作机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%80%9A%E9%81%93%E5%A2%9E%E9%95%BF%E7%9A%84%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6"><span class="toc-number">1.2.3.</span> <span class="toc-text">3. 通道增长的具体数学</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82"><span class="toc-number">1.3.</span> <span class="toc-text">🔑 关键技术细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Bottleneck-Layer%E7%9A%84%E7%B2%BE%E7%A1%AE%E4%BD%9C%E7%94%A8"><span class="toc-number">1.3.1.</span> <span class="toc-text">1. Bottleneck Layer的精确作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Transition-Layer-vs-Bottleneck"><span class="toc-number">1.3.2.</span> <span class="toc-text">2. Transition Layer vs Bottleneck</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%8B%BC%E6%8E%A5-concat-vs-%E5%8A%A0%E6%B3%95-add-%E7%9A%84%E6%9C%AC%E8%B4%A8%E5%8C%BA%E5%88%AB"><span class="toc-number">1.3.3.</span> <span class="toc-text">3. 拼接(concat) vs 加法(add)的本质区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E5%9C%A8%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%AD%E7%9A%84%E7%89%B9%E6%AE%8A%E4%BB%B7%E5%80%BC"><span class="toc-number">1.4.</span> <span class="toc-text">🎯 在医学影像中的特殊价值</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%89%B9%E5%BE%81%E5%A4%8D%E7%94%A8%E4%BC%98%E5%8A%BF"><span class="toc-number">1.4.1.</span> <span class="toc-text">1. 特征复用优势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%92%88%E5%AF%B9%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E7%9A%84%E7%89%B9%E6%80%A7%E9%80%82%E9%85%8D"><span class="toc-number">1.4.2.</span> <span class="toc-text">2. 针对医学图像的特性适配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AE%9E%E9%99%85%E9%85%8D%E7%BD%AE%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.4.3.</span> <span class="toc-text">3. 实际配置建议</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9A%A1-%E8%AE%AD%E7%BB%83%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8A%80%E5%B7%A7"><span class="toc-number">1.5.</span> <span class="toc-text">⚡ 训练与优化技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5"><span class="toc-number">1.5.1.</span> <span class="toc-text">1. 内存优化策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%8C%BB%E5%AD%A6%E6%95%B0%E6%8D%AE%E7%89%B9%E6%AE%8A%E5%A4%84%E7%90%86"><span class="toc-number">1.5.2.</span> <span class="toc-text">2. 医学数据特殊处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%84-%E4%B8%8E%E5%85%B6%E4%BB%96%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AF%B9%E6%AF%94%E7%90%86%E8%A7%A3"><span class="toc-number">1.6.</span> <span class="toc-text">🔄 与其他模型的对比理解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BF%A1%E6%81%AF%E4%BF%9D%E7%95%99%E8%83%BD%E5%8A%9B%E5%AF%B9%E6%AF%94"><span class="toc-number">1.6.1.</span> <span class="toc-text">1. 信息保留能力对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%9C%A8%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E9%80%89%E6%8B%A9%E6%8C%87%E5%8D%97"><span class="toc-number">1.6.2.</span> <span class="toc-text">2. 在医学影像任务中的选择指南</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%92%A1-%E5%85%B3%E9%94%AE%E6%B4%9E%E5%AF%9F%E6%80%BB%E7%BB%93"><span class="toc-number">1.7.</span> <span class="toc-text">💡 关键洞察总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A0%B8%E5%BF%83%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">1.7.1.</span> <span class="toc-text">1. 核心创新点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%9C%A8%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%AD%E7%9A%84%E7%8B%AC%E7%89%B9%E4%BB%B7%E5%80%BC"><span class="toc-number">1.7.2.</span> <span class="toc-text">2. 在医学影像中的独特价值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AE%9E%E7%94%A8%E8%A6%81%E7%82%B9"><span class="toc-number">1.7.3.</span> <span class="toc-text">3. 实用要点</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/27/SENet/" title="Squeeze-and-Excitation Networks (SENet)">Squeeze-and-Excitation Networks (SENet)</a><time datetime="2025-11-27T08:22:00.000Z" title="发表于 2025-11-27 16:22:00">2025-11-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/26/DenseNet/" title="DenseNet论文学习笔">DenseNet论文学习笔</a><time datetime="2025-11-26T13:18:00.000Z" title="发表于 2025-11-26 21:18:00">2025-11-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/19/%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/" title="模型学习分类">模型学习分类</a><time datetime="2025-11-19T06:21:00.000Z" title="发表于 2025-11-19 14:21:00">2025-11-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/13/MACM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--MACM">MM-UNet 论文学习笔记--MACM</a><time datetime="2025-11-13T06:50:00.000Z" title="发表于 2025-11-13 14:50:00">2025-11-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/13/GCM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--GCM">MM-UNet 论文学习笔记--GCM</a><time datetime="2025-11-13T05:30:00.000Z" title="发表于 2025-11-13 13:30:00">2025-11-13</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Soong</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>