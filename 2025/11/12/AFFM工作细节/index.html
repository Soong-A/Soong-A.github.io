<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>MM-UNet 论文学习笔记--AFFM (自适应特征融合模块) | Soong's blog</title><meta name="author" content="Soong"><meta name="copyright" content="Soong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="AFFM (自适应特征融合模块) 学习笔记 🎯 解决的问题传统方法的缺陷：  直接将高层特征（轮廓信息）与低层特征（细节信息）拼接 导致背景噪声混入有用信息中 影响最终分割的精准度  🏗️ 模块设计思路AFFM就像一个智能的制图师，能够智能地融合两种不同类型的地图：  低层特征 &#x3D; “细节地图” ✅ 优点：包含丰富的边缘、纹理等细节信息 ❌ 缺点：混杂大量背景噪声，缺乏整体概念">
<meta property="og:type" content="article">
<meta property="og:title" content="MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)">
<meta property="og:url" content="https://soong-a.github.io/2025/11/12/AFFM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/index.html">
<meta property="og:site_name" content="Soong&#39;s blog">
<meta property="og:description" content="AFFM (自适应特征融合模块) 学习笔记 🎯 解决的问题传统方法的缺陷：  直接将高层特征（轮廓信息）与低层特征（细节信息）拼接 导致背景噪声混入有用信息中 影响最终分割的精准度  🏗️ 模块设计思路AFFM就像一个智能的制图师，能够智能地融合两种不同类型的地图：  低层特征 &#x3D; “细节地图” ✅ 优点：包含丰富的边缘、纹理等细节信息 ❌ 缺点：混杂大量背景噪声，缺乏整体概念">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://soong-a.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2025-11-12T13:50:00.000Z">
<meta property="article:modified_time" content="2025-11-12T14:07:34.995Z">
<meta property="article:author" content="Soong">
<meta property="article:tag" content="图像处理">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="基础知识">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://soong-a.github.io/img/avatar.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)",
  "url": "https://soong-a.github.io/2025/11/12/AFFM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/",
  "image": "https://soong-a.github.io/img/avatar.jpg",
  "datePublished": "2025-11-12T13:50:00.000Z",
  "dateModified": "2025-11-12T14:07:34.995Z",
  "author": [
    {
      "@type": "Person",
      "name": "Soong",
      "url": "https://soong-a.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://soong-a.github.io/2025/11/12/AFFM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/index.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Soong's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-11-12T13:50:00.000Z" title="发表于 2025-11-12 21:50:00">2025-11-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-11-12T14:07:34.995Z" title="更新于 2025-11-12 22:07:34">2025-11-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90/">医学图像分析</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90/A-mixed-Mamba-U%E2%80%91net-for-prostate-segmentation-in-MR-images/">A mixed Mamba U‑net for prostate segmentation in MR images</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h1 id="AFFM-自适应特征融合模块-学习笔记"><a href="#AFFM-自适应特征融合模块-学习笔记" class="headerlink" title="AFFM (自适应特征融合模块) 学习笔记"></a>AFFM (自适应特征融合模块) 学习笔记</h1><p><img src="C:\Users\92631\AppData\Roaming\Typora\typora-user-images\image-20251112214749804.png" alt="image-20251112214749804"></p>
<h2 id="🎯-解决的问题"><a href="#🎯-解决的问题" class="headerlink" title="🎯 解决的问题"></a>🎯 解决的问题</h2><p><strong>传统方法的缺陷：</strong></p>
<ul>
<li>直接将高层特征（轮廓信息）与低层特征（细节信息）拼接</li>
<li>导致背景噪声混入有用信息中</li>
<li>影响最终分割的精准度</li>
</ul>
<h2 id="🏗️-模块设计思路"><a href="#🏗️-模块设计思路" class="headerlink" title="🏗️ 模块设计思路"></a>🏗️ 模块设计思路</h2><p>AFFM就像一个<strong>智能的制图师</strong>，能够智能地融合两种不同类型的地图：</p>
<ul>
<li><strong>低层特征</strong> &#x3D; <strong>“细节地图”</strong><ul>
<li>✅ 优点：包含丰富的边缘、纹理等细节信息</li>
<li>❌ 缺点：混杂大量背景噪声，缺乏整体概念</li>
</ul>
</li>
<li><strong>高层特征</strong> &#x3D; <strong>“轮廓地图”</strong><ul>
<li>✅ 优点：包含前列腺整体形状的语义信息</li>
<li>❌ 缺点：缺乏精确定位的细节</li>
</ul>
</li>
</ul>
<h2 id="🔄-三步骤工作流程"><a href="#🔄-三步骤工作流程" class="headerlink" title="🔄 三步骤工作流程"></a>🔄 三步骤工作流程</h2><h3 id="第一步：特征对齐与拼接"><a href="#第一步：特征对齐与拼接" class="headerlink" title="第一步：特征对齐与拼接"></a>第一步：特征对齐与拼接</h3><p>&#x2F;img&#x2F;屏幕截图 2025-11-12 215920.png</p>
<p>临时特征 &#x3D; 拼接(上采样(高层特征), 低层特征)</p>
<ul>
<li>动作：将高层特征上采样到与低层特征相同尺寸</li>
<li><strong>目的</strong>：让两种特征可以在同一尺度上进行融合</li>
</ul>
<h3 id="第二步：智能权重计算（核心创新）"><a href="#第二步：智能权重计算（核心创新）" class="headerlink" title="第二步：智能权重计算（核心创新）"></a>第二步：智能权重计算（核心创新）</h3><p>&#x2F;img&#x2F;屏幕截图 2025-11-12 220019.png</p>
<p>重要性权重 &#x3D; Sigmoid(全连接层2(全连接层1(全局平均池化(临时特征))))</p>
<p><strong>详细分解：</strong></p>
<ol>
<li><strong>全局平均池化</strong>：对每个特征通道计算平均值，得到通道的”重要性概览”</li>
<li><strong>全连接层1</strong>：分析这些通道的重要性关系</li>
<li><strong>全连接层2</strong>：进一步提炼重要性信息</li>
<li><strong>Sigmoid函数</strong>：将重要性转换为0-1之间的权重值<ul>
<li><code>α ≈ 1</code>：该通道特征很重要，需要<strong>保留</strong></li>
<li><code>α ≈ 0</code>：该通道特征是噪声，需要<strong>抑制</strong></li>
</ul>
</li>
</ol>
<h3 id="第三步：精准特征融合"><a href="#第三步：精准特征融合" class="headerlink" title="第三步：精准特征融合"></a>第三步：精准特征融合</h3><p>&#x2F;img&#x2F;屏幕截图 2025-11-12 220035.png</p>
<p>最终输出 &#x3D; (重要性权重 × 低层特征) + 高层特征（去除噪声）</p>
<p><strong>设计原理分析：</strong></p>
<ul>
<li><strong>为什么只对低层特征加权？</strong><ul>
<li>低层特征”鱼龙混杂”，需要净化过滤</li>
<li>高层特征已经比较”干净”，包含重要语义信息</li>
<li>保护高层特征的完整性，避免扭曲已有语义</li>
</ul>
</li>
<li><strong>为什么用加法而不是拼接？</strong><ul>
<li>加法操作更简单，计算量更小</li>
<li>能够自然地融合两种特征的信息</li>
<li>避免引入额外的参数和复杂度</li>
</ul>
</li>
</ul>
<h2 id="💡-核心优势"><a href="#💡-核心优势" class="headerlink" title="💡 核心优势"></a>💡 核心优势</h2><h3 id="1-智能噪声抑制"><a href="#1-智能噪声抑制" class="headerlink" title="1. 智能噪声抑制"></a>1. 智能噪声抑制</h3><ul>
<li>自动识别并抑制背景噪声</li>
<li>保留对分割有用的边缘和纹理信息</li>
</ul>
<h3 id="2-精准特征选择"><a href="#2-精准特征选择" class="headerlink" title="2. 精准特征选择"></a>2. 精准特征选择</h3><ul>
<li>不是简单粗暴地拼接所有特征</li>
<li>根据任务需求自适应选择重要特征</li>
</ul>
<h3 id="3-端到端学习"><a href="#3-端到端学习" class="headerlink" title="3. 端到端学习"></a>3. 端到端学习</h3><ul>
<li>整个注意力机制可以端到端训练</li>
<li>网络自动学习什么特征对前列腺分割最重要</li>
</ul>
<h2 id="📊-在MM-UNet中的作用"><a href="#📊-在MM-UNet中的作用" class="headerlink" title="📊 在MM-UNet中的作用"></a>📊 在MM-UNet中的作用</h2><p>AFFM位于解码器中，在每次上采样后使用：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">上采样 → AFFM融合 → MACM优化 → 输出到下一层</span><br></pre></td></tr></table></figure>

<p>通过逐层的AFFM融合，MM-UNet能够：</p>
<ul>
<li>在早期层保留更多细节信息</li>
<li>在深层补充全局语义信息</li>
<li>最终实现精准的前列腺边界定位</li>
</ul>
<h2 id="🎯-关键理解要点"><a href="#🎯-关键理解要点" class="headerlink" title="🎯 关键理解要点"></a>🎯 关键理解要点</h2><ol>
<li><strong>AFFM不是简单的特征拼接</strong>，而是<strong>智能的特征选择</strong></li>
<li><strong>注意力机制是关键</strong>，让网络自己学会”看重点”</li>
<li><strong>设计很巧妙</strong>：只净化需要净化的（低层特征），保护已经很好的（高层特征）</li>
<li><strong>整个过程可训练</strong>，不需要人工设定规则</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://soong-a.github.io">Soong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://soong-a.github.io/2025/11/12/AFFM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/">https://soong-a.github.io/2025/11/12/AFFM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://soong-a.github.io" target="_blank">Soong's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/11/13/GCM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--GCM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">MM-UNet 论文学习笔记--GCM</div></div><div class="info-2"><div class="info-item-1">Global Context-aware Module (GCM)概述GCM是一个用于医学图像分割的全局上下文理解模块，通过结合CNN的局部特征提取能力和Mamba的长序列建模能力，实现高效的全局上下文捕获。 1. GCM整体架构flowchart TD     A[输入特征图&lt;br&gt;B×C×H×W×D] --&gt; B[残差块1&lt;br&gt;Conv+IN+LeakyReLU]     B --&gt; C[残差块2&lt;br&gt;Conv+IN+LeakyReLU]     C --&gt; D[重塑序列&lt;br&gt;B×L×C&lt;br&gt;L=H×W×D]     D --&gt; E[Layer Normalization]     E --&gt; F[Mamba块]     F --&gt; G[重塑回空间结构&lt;br&gt;B×C×H×W×D]     G --&gt; H[输出特征图]          class A,B,C,D,E,F,G,H normal;          classDef normal fill:n...</div></div></div></a><a class="pagination-related" href="/2025/11/12/3D%20Res2Net%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--3D Res2Net的改造和使用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">MM-UNet 论文学习笔记--3D Res2Net的改造和使用</div></div><div class="info-2"><div class="info-item-1">编码器细节：3D Res2Net的改造和使用核心思想我们选用了一个叫Res2Net的”高手”来做编码器，但它本来是处理2D普通照片的。我们通过一些巧妙的”改造”，让它能处理我们的3D医学图像，并且还让它继承了之前在普通照片上学到的”经验”。 为什么选择Res2Net？Res2Net的每个残差块内部都有分层式的残差连接，这让它能更有效地在粒度级别使用多尺度信息，扩展每一层的感受野。 就像工人同时拿着多种不同倍数的放大镜在工作：  一个小放大镜看细微的纹理和边缘（小尺度特征） 一个中倍放大镜看局部的结构（中尺度特征） 一个大倍放大镜看大致的轮廓（大尺度特征）  这对于边界模糊的前列腺图像来说，非常有用。 编码器的具体工作流程第一步：初始卷积（Convolution Stem）给定的图像首先通过一个卷积茎，它由并行的3×3×3卷积和1×1×1卷积组成，后面跟着求和操作。  3×3×3卷积：捕捉图像中小范围的、基本的局部特征（比如某个点是不是边缘） 1×1×1卷积：主要负责调整数据的通道数，为后续处理做准备 最后把两个结果相加，得到一个包含丰富基础信息的特征图  第二步：核心特征提取然后...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/12/3D%20Res2Net%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--3D Res2Net的改造和使用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-12</div><div class="info-item-2">MM-UNet 论文学习笔记--3D Res2Net的改造和使用</div></div><div class="info-2"><div class="info-item-1">编码器细节：3D Res2Net的改造和使用核心思想我们选用了一个叫Res2Net的”高手”来做编码器，但它本来是处理2D普通照片的。我们通过一些巧妙的”改造”，让它能处理我们的3D医学图像，并且还让它继承了之前在普通照片上学到的”经验”。 为什么选择Res2Net？Res2Net的每个残差块内部都有分层式的残差连接，这让它能更有效地在粒度级别使用多尺度信息，扩展每一层的感受野。 就像工人同时拿着多种不同倍数的放大镜在工作：  一个小放大镜看细微的纹理和边缘（小尺度特征） 一个中倍放大镜看局部的结构（中尺度特征） 一个大倍放大镜看大致的轮廓（大尺度特征）  这对于边界模糊的前列腺图像来说，非常有用。 编码器的具体工作流程第一步：初始卷积（Convolution Stem）给定的图像首先通过一个卷积茎，它由并行的3×3×3卷积和1×1×1卷积组成，后面跟着求和操作。  3×3×3卷积：捕捉图像中小范围的、基本的局部特征（比如某个点是不是边缘） 1×1×1卷积：主要负责调整数据的通道数，为后续处理做准备 最后把两个结果相加，得到一个包含丰富基础信息的特征图  第二步：核心特征提取然后...</div></div></div></a><a class="pagination-related" href="/2025/11/12/A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images%20%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="MM-UNet 论文学习笔记--AFFM GCM MACM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-12</div><div class="info-item-2">MM-UNet 论文学习笔记--AFFM GCM MACM</div></div><div class="info-2"><div class="info-item-1">MM-UNet：3D前列腺MR图像分割方法核心目标：为什么要做这个研究？医生有一张前列腺的3D核磁共振（MR）图像，他们需要精确地知道图像中哪些像素是属于前列腺的。这个过程叫做”分割”。 手动分割的问题：非常耗时、费力，而且不同医生的判断可能会有差异。 自动分割的挑战：计算机来做这件事，面临三个主要难题：  图像质量差：MR图像背景杂乱（噪声多），前列腺边界模糊。 关系复杂：前列腺的形状和它周围的组织（膀胱、直肠等）是相互关联的，计算机需要理解整个图像的”上下文”才能准确判断边界。 数据特殊：3D的MR图像在上下、左右、前后三个方向的分辨率（清晰度）是不一样的。这导致传统的3D处理方法效果不好。  MM-UNET就是为了解决这三个挑战而设计的。 创新点一：自适应特征融合模块 (AFFM) – 解决”如何精准融合信息”1. 为什么需要它？在分割网络中，存在两种信息：  低级特征：来自网络的浅层，包含丰富的细节信息（如边缘、纹理），但也混有很多背景噪声。 高级特征：来自网络的深层，包含抽象的语义信息（知道”这是前列腺”），但缺乏细节，比较粗糙。  传统方法简单地把这两种特征拼接在一起...</div></div></div></a><a class="pagination-related" href="/2025/11/11/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90%20A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images/" title="背景分析 A mixed Mamba U‑net for prostate segmentation in MR images"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-11</div><div class="info-item-2">背景分析 A mixed Mamba U‑net for prostate segmentation in MR images</div></div><div class="info-2"><div class="info-item-1">flowchart TD     A[&quot;📍 起点: 前列腺MRI分割&quot;]:::startNode --&gt; B[&quot;⚠️ 问题: 正负样本不平衡&quot;]:::problemNode          B --&gt; S1      subgraph S1 [第一阶段: 基于CNN的改进]         direction TB         C[&quot;🎯 V-Net&lt;br&gt;3D U-Net + Dice Loss&quot;]:::solutionNode         E[&quot;🔍 USE-Net&lt;br&gt;U-Net + SE模块&quot;]:::solutionNode                  C --&gt; D&#123;&quot;CNN固有局限性&quot;&#125;:::challengeNode         E --&gt; D         D --&gt; F[&quot;🚫 问题: 难以建模长程依赖（只能提取局部特征，难以理解距离较远的部分之间的关系）...</div></div></div></a><a class="pagination-related" href="/2025/11/13/GCM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--GCM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-13</div><div class="info-item-2">MM-UNet 论文学习笔记--GCM</div></div><div class="info-2"><div class="info-item-1">Global Context-aware Module (GCM)概述GCM是一个用于医学图像分割的全局上下文理解模块，通过结合CNN的局部特征提取能力和Mamba的长序列建模能力，实现高效的全局上下文捕获。 1. GCM整体架构flowchart TD     A[输入特征图&lt;br&gt;B×C×H×W×D] --&gt; B[残差块1&lt;br&gt;Conv+IN+LeakyReLU]     B --&gt; C[残差块2&lt;br&gt;Conv+IN+LeakyReLU]     C --&gt; D[重塑序列&lt;br&gt;B×L×C&lt;br&gt;L=H×W×D]     D --&gt; E[Layer Normalization]     E --&gt; F[Mamba块]     F --&gt; G[重塑回空间结构&lt;br&gt;B×C×H×W×D]     G --&gt; H[输出特征图]          class A,B,C,D,E,F,G,H normal;          classDef normal fill:n...</div></div></div></a><a class="pagination-related" href="/2025/11/11/%E9%98%88%E5%80%BC%E3%80%81%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E6%BB%A4%E6%B3%A2%E5%99%A8%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AF%B9%E6%AF%94/" title="阈值方法、边缘检测滤波器和机器学习技术对比"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-11</div><div class="info-item-2">阈值方法、边缘检测滤波器和机器学习技术对比</div></div><div class="info-2"><div class="info-item-1">图像处理技术对比：阈值方法、边缘检测与机器学习目录 定义 相同点 区别 应用场景 总结  定义阈值方法阈值方法是一种简单的图像分割技术，通过设置一个或多个阈值将图像像素分为两类或多类。 关键特性：  将灰度图像转换为二值图像 像素值高于阈值设为白色(1)，低于阈值设为黑色(0) 可以是全局阈值或自适应阈值  示例： Otsu阈值法、自适应阈值法 边缘检测滤波器边缘检测滤波器用于识别图像中像素值急剧变化的区域（边缘）。 关键特性：  通过卷积核计算图像的梯度或导数 输出边缘图，强调轮廓信息 对噪声敏感但能捕捉细节  示例： Sobel滤波器、Canny边缘检测器 机器学习技术机器学习技术涉及使用算法从数据中自动学习模式和特征。 关键特性：  无需显式编程，自动学习 包括监督学习、无监督学习和强化学习 需要训练数据和模型优化  示例： CNN图像分类、SVM对象检测 相同点 共同应用领域：图像处理、计算机视觉、模式识别 核心目标：从图像中提取有意义信息，简化图像表示 预处理流程：传统方法常作为机器学习的预处理步骤 自动化特性：均可实现不同程度的自动化处理  区别   特性 阈值方法 ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Soong</div><div class="author-info-description">有关机器学习，力扣代码训练等，欢迎探索</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Soong-A" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:926315593@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AFFM-%E8%87%AA%E9%80%82%E5%BA%94%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E6%A8%A1%E5%9D%97-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">AFFM (自适应特征融合模块) 学习笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">🎯 解决的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8F%97%EF%B8%8F-%E6%A8%A1%E5%9D%97%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF"><span class="toc-number">1.2.</span> <span class="toc-text">🏗️ 模块设计思路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%84-%E4%B8%89%E6%AD%A5%E9%AA%A4%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">1.3.</span> <span class="toc-text">🔄 三步骤工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E7%89%B9%E5%BE%81%E5%AF%B9%E9%BD%90%E4%B8%8E%E6%8B%BC%E6%8E%A5"><span class="toc-number">1.3.1.</span> <span class="toc-text">第一步：特征对齐与拼接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E6%99%BA%E8%83%BD%E6%9D%83%E9%87%8D%E8%AE%A1%E7%AE%97%EF%BC%88%E6%A0%B8%E5%BF%83%E5%88%9B%E6%96%B0%EF%BC%89"><span class="toc-number">1.3.2.</span> <span class="toc-text">第二步：智能权重计算（核心创新）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E7%B2%BE%E5%87%86%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88"><span class="toc-number">1.3.3.</span> <span class="toc-text">第三步：精准特征融合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%92%A1-%E6%A0%B8%E5%BF%83%E4%BC%98%E5%8A%BF"><span class="toc-number">1.4.</span> <span class="toc-text">💡 核心优势</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%99%BA%E8%83%BD%E5%99%AA%E5%A3%B0%E6%8A%91%E5%88%B6"><span class="toc-number">1.4.1.</span> <span class="toc-text">1. 智能噪声抑制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%B2%BE%E5%87%86%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-number">1.4.2.</span> <span class="toc-text">2. 精准特征选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%AB%AF%E5%88%B0%E7%AB%AF%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.4.3.</span> <span class="toc-text">3. 端到端学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8A-%E5%9C%A8MM-UNet%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">1.5.</span> <span class="toc-text">📊 在MM-UNet中的作用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E5%85%B3%E9%94%AE%E7%90%86%E8%A7%A3%E8%A6%81%E7%82%B9"><span class="toc-number">1.6.</span> <span class="toc-text">🎯 关键理解要点</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/13/GCM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--GCM">MM-UNet 论文学习笔记--GCM</a><time datetime="2025-11-13T05:30:00.000Z" title="发表于 2025-11-13 13:30:00">2025-11-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/12/AFFM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)">MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)</a><time datetime="2025-11-12T13:50:00.000Z" title="发表于 2025-11-12 21:50:00">2025-11-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/12/3D%20Res2Net%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--3D Res2Net的改造和使用">MM-UNet 论文学习笔记--3D Res2Net的改造和使用</a><time datetime="2025-11-12T13:18:00.000Z" title="发表于 2025-11-12 21:18:00">2025-11-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/12/A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images%20%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="MM-UNet 论文学习笔记--AFFM GCM MACM">MM-UNet 论文学习笔记--AFFM GCM MACM</a><time datetime="2025-11-12T12:18:00.000Z" title="发表于 2025-11-12 20:18:00">2025-11-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/11/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90%20A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images/" title="背景分析 A mixed Mamba U‑net for prostate segmentation in MR images">背景分析 A mixed Mamba U‑net for prostate segmentation in MR images</a><time datetime="2025-11-11T07:18:00.000Z" title="发表于 2025-11-11 15:18:00">2025-11-11</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Soong</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>