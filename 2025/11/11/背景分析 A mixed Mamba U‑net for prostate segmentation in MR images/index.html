<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>背景分析 A mixed Mamba U‑net for prostate segmentation in MR images | Soong's blog</title><meta name="author" content="Soong"><meta name="copyright" content="Soong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="flowchart TD     A[&quot;📍 起点: 前列腺MRI分割&quot;]:::startNode --&gt; B[&quot;⚠️ 问题: 正负样本不平衡&quot;]:::problemNode          B --&gt; S1      subgraph S1 [第一阶段: 基于CNN的改进]         direction TB         C[&amp;qu">
<meta property="og:type" content="article">
<meta property="og:title" content="背景分析 A mixed Mamba U‑net for prostate segmentation in MR images">
<meta property="og:url" content="https://soong-a.github.io/2025/11/11/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90%20A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images/index.html">
<meta property="og:site_name" content="Soong&#39;s blog">
<meta property="og:description" content="flowchart TD     A[&quot;📍 起点: 前列腺MRI分割&quot;]:::startNode --&gt; B[&quot;⚠️ 问题: 正负样本不平衡&quot;]:::problemNode          B --&gt; S1      subgraph S1 [第一阶段: 基于CNN的改进]         direction TB         C[&amp;qu">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://soong-a.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2025-11-11T07:18:00.000Z">
<meta property="article:modified_time" content="2025-11-11T08:25:03.839Z">
<meta property="article:author" content="Soong">
<meta property="article:tag" content="图像处理">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="基础知识">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://soong-a.github.io/img/avatar.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "背景分析 A mixed Mamba U‑net for prostate segmentation in MR images",
  "url": "https://soong-a.github.io/2025/11/11/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90%20A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images/",
  "image": "https://soong-a.github.io/img/avatar.jpg",
  "datePublished": "2025-11-11T07:18:00.000Z",
  "dateModified": "2025-11-11T08:25:03.839Z",
  "author": [
    {
      "@type": "Person",
      "name": "Soong",
      "url": "https://soong-a.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://soong-a.github.io/2025/11/11/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90%20A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '背景分析 A mixed Mamba U‑net for prostate segmentation in MR images',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/index.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Soong's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">背景分析 A mixed Mamba U‑net for prostate segmentation in MR images</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">背景分析 A mixed Mamba U‑net for prostate segmentation in MR images</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-11-11T07:18:00.000Z" title="发表于 2025-11-11 15:18:00">2025-11-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-11-11T08:25:03.839Z" title="更新于 2025-11-11 16:25:03">2025-11-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90/">医学图像分析</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90/A-mixed-Mamba-U%E2%80%91net-for-prostate-segmentation-in-MR-images/">A mixed Mamba U‑net for prostate segmentation in MR images</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><pre><code class="highlight mermaid">flowchart TD
    A[&quot;📍 起点: 前列腺MRI分割&quot;]:::startNode --&gt; B[&quot;⚠️ 问题: 正负样本不平衡&quot;]:::problemNode
    
    B --&gt; S1

    subgraph S1 [第一阶段: 基于CNN的改进]
        direction TB
        C[&quot;🎯 V-Net&lt;br&gt;3D U-Net + Dice Loss&quot;]:::solutionNode
        E[&quot;🔍 USE-Net&lt;br&gt;U-Net + SE模块&quot;]:::solutionNode
        
        C --&gt; D&#123;&quot;CNN固有局限性&quot;&#125;:::challengeNode
        E --&gt; D
        D --&gt; F[&quot;🚫 问题: 难以建模长程依赖（只能提取局部特征，难以理解距离较远的部分之间的关系）&quot;]:::problemNode
    end

    F --&gt; G[&quot;💡 动机: 解决长程依赖问题&quot;]:::motivationNode
    G --&gt; S2

    subgraph S2 [第二阶段: Transformer的引入]
        direction TB
        H[&quot;🌟 Transformer核心机制&lt;br&gt;多头自注意力MSA&quot;]:::innovationNode
        H --&gt; I[&quot;⚡ CCTUnet&lt;br&gt;卷积与Transformer耦合&quot;]:::solutionNode
    end

    I --&gt; J[&quot;🔥 新问题: MSA的二次计算复杂度（两两进行计算，算力要求大）&quot;]:::problemNode
    J --&gt; S3

    subgraph S3 [第三阶段: 当前挑战与未来]
        direction TB
        K[&quot;🎯 核心挑战&lt;br&gt;在保持CNN计算效率的同时&lt;br&gt;有效提升其建模长程依赖的能力&quot;]:::challengeNode
        K --&gt; L[&quot;❓ 现状: 尚无明确解决方案&quot;]:::futureNode
    end

    S1 --&gt; S2
    S2 --&gt; S3

    %% 自定义样式 - 透明背景 + 圆角
    classDef startNode fill:transparent,stroke:#4A90E2,stroke-width:2px,color:#333,rx:8px,ry:8px
    classDef problemNode fill:transparent,stroke:#E74C3C,stroke-width:2px,stroke-dasharray:5 5,color:#333,rx:8px,ry:8px
    classDef solutionNode fill:transparent,stroke:#27AE60,stroke-width:2px,color:#333,rx:8px,ry:8px
    classDef challengeNode fill:transparent,stroke:#F39C12,stroke-width:2px,color:#333,rx:8px,ry:8px
    classDef motivationNode fill:transparent,stroke:#9B59B6,stroke-width:2px,color:#333,rx:8px,ry:8px
    classDef innovationNode fill:transparent,stroke:#3498DB,stroke-width:2px,color:#333,rx:8px,ry:8px
    classDef futureNode fill:transparent,stroke:#95A5A6,stroke-width:2px,color:#333,rx:8px,ry:8px
    classDef subgraphNode fill:transparent,stroke:#CCCCCC,stroke-width:1px,stroke-dasharray:5 5,color:#666,rx:15px,ry:15px
    
    class A startNode
    class B,F,J problemNode
    class C,E,H,I solutionNode
    class D,G,K challengeNode
    class L futureNode
    class S1,S2,S3 subgraphNode</code></pre>

<h2 id="🧩-CNN的局限性：”管中窥豹”问题"><a href="#🧩-CNN的局限性：”管中窥豹”问题" class="headerlink" title="🧩 CNN的局限性：”管中窥豹”问题"></a>🧩 CNN的局限性：”管中窥豹”问题</h2><h3 id="比喻解释"><a href="#比喻解释" class="headerlink" title="比喻解释"></a>比喻解释</h3><p>想象你正在拼一张巨大的拼图，但每次只能通过一个<strong>很小的硬纸板筒</strong>去看图。</p>
<h3 id="具体表现"><a href="#具体表现" class="headerlink" title="具体表现"></a>具体表现</h3><ul>
<li><strong>视野狭窄</strong>：一次只能看到图像的一小部分</li>
<li><strong>缺乏全局观</strong>：能看清局部细节，但不知道这些细节在整体中的位置和关系</li>
<li><strong>连接断裂</strong>：无法理解距离较远部分之间的关联</li>
</ul>
<h3 id="在实际应用中的影响"><a href="#在实际应用中的影响" class="headerlink" title="在实际应用中的影响"></a>在实际应用中的影响</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">❌ 能识别出&quot;这是一片肿瘤细胞&quot;</span><br><span class="line">❌ 但无法判断这片肿瘤在整个器官中的位置</span><br><span class="line">❌ 难以理解肿瘤与周围组织的完整关系</span><br><span class="line">❌ 可能漏掉分散但相关的病灶区域</span><br></pre></td></tr></table></figure>



<h2 id="💥-Transformer的局限性：”全员会议”成本问题"><a href="#💥-Transformer的局限性：”全员会议”成本问题" class="headerlink" title="💥 Transformer的局限性：”全员会议”成本问题"></a>💥 Transformer的局限性：”全员会议”成本问题</h2><h3 id="比喻解释-1"><a href="#比喻解释-1" class="headerlink" title="比喻解释"></a>比喻解释</h3><p>为了解决CNN的视野问题，你决定召开<strong>全员大会</strong> - 让拼图的每一小块都与其他所有小块对话。</p>
<h3 id="具体表现-1"><a href="#具体表现-1" class="headerlink" title="具体表现"></a>具体表现</h3><ul>
<li><strong>计算量爆炸</strong>：对话次数 &#x3D; 小块数量 × 小块数量</li>
<li><strong>资源消耗大</strong>：需要巨大的内存和算力</li>
<li><strong>效率低下</strong>：处理高分辨率图像时速度极慢</li>
</ul>
<h3 id="数学关系"><a href="#数学关系" class="headerlink" title="数学关系"></a>数学关系</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10个小块 → 100次对话</span><br><span class="line">100个小块 → 10,000次对话  </span><br><span class="line">1000个小块 → 1,000,000次对话</span><br></pre></td></tr></table></figure>



<h2 id="📊-两种模型对比"><a href="#📊-两种模型对比" class="headerlink" title="📊 两种模型对比"></a>📊 两种模型对比</h2><table>
<thead>
<tr>
<th align="left">模型类型</th>
<th align="left">工作原理</th>
<th align="left">优势</th>
<th align="left">局限性</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>CNN</strong></td>
<td align="left">局部扫描 逐步分析</td>
<td align="left">✅ 计算效率高 ✅ 硬件要求低 ✅ 擅长局部特征</td>
<td align="left">❌ 视野有限 ❌ 全局理解差 ❌ 长程依赖弱</td>
</tr>
<tr>
<td align="left"><strong>Transformer</strong></td>
<td align="left">全局关注 全员互动</td>
<td align="left">✅ 全局视野好 ✅ 长程依赖强 ✅ 上下文理解深</td>
<td align="left">❌ 计算成本高 ❌ 内存消耗大 ❌ 训练速度慢</td>
</tr>
</tbody></table>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://soong-a.github.io">Soong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://soong-a.github.io/2025/11/11/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90%20A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images/">https://soong-a.github.io/2025/11/11/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90%20A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://soong-a.github.io" target="_blank">Soong's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/11/12/A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images%20%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="MM-UNet 论文学习笔记--AFFM GCM MACM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">MM-UNet 论文学习笔记--AFFM GCM MACM</div></div><div class="info-2"><div class="info-item-1">MM-UNet：3D前列腺MR图像分割方法核心目标：为什么要做这个研究？医生有一张前列腺的3D核磁共振（MR）图像，他们需要精确地知道图像中哪些像素是属于前列腺的。这个过程叫做”分割”。 手动分割的问题：非常耗时、费力，而且不同医生的判断可能会有差异。 自动分割的挑战：计算机来做这件事，面临三个主要难题：  图像质量差：MR图像背景杂乱（噪声多），前列腺边界模糊。 关系复杂：前列腺的形状和它周围的组织（膀胱、直肠等）是相互关联的，计算机需要理解整个图像的”上下文”才能准确判断边界。 数据特殊：3D的MR图像在上下、左右、前后三个方向的分辨率（清晰度）是不一样的。这导致传统的3D处理方法效果不好。  MM-UNET就是为了解决这三个挑战而设计的。 创新点一：自适应特征融合模块 (AFFM) – 解决”如何精准融合信息”1. 为什么需要它？在分割网络中，存在两种信息：  低级特征：来自网络的浅层，包含丰富的细节信息（如边缘、纹理），但也混有很多背景噪声。 高级特征：来自网络的深层，包含抽象的语义信息（知道”这是前列腺”），但缺乏细节，比较粗糙。  传统方法简单地把这两种特征拼接在一起...</div></div></div></a><a class="pagination-related" href="/2025/11/11/%E9%98%88%E5%80%BC%E3%80%81%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E6%BB%A4%E6%B3%A2%E5%99%A8%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AF%B9%E6%AF%94/" title="阈值方法、边缘检测滤波器和机器学习技术对比"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">阈值方法、边缘检测滤波器和机器学习技术对比</div></div><div class="info-2"><div class="info-item-1">图像处理技术对比：阈值方法、边缘检测与机器学习目录 定义 相同点 区别 应用场景 总结  定义阈值方法阈值方法是一种简单的图像分割技术，通过设置一个或多个阈值将图像像素分为两类或多类。 关键特性：  将灰度图像转换为二值图像 像素值高于阈值设为白色(1)，低于阈值设为黑色(0) 可以是全局阈值或自适应阈值  示例： Otsu阈值法、自适应阈值法 边缘检测滤波器边缘检测滤波器用于识别图像中像素值急剧变化的区域（边缘）。 关键特性：  通过卷积核计算图像的梯度或导数 输出边缘图，强调轮廓信息 对噪声敏感但能捕捉细节  示例： Sobel滤波器、Canny边缘检测器 机器学习技术机器学习技术涉及使用算法从数据中自动学习模式和特征。 关键特性：  无需显式编程，自动学习 包括监督学习、无监督学习和强化学习 需要训练数据和模型优化  示例： CNN图像分类、SVM对象检测 相同点 共同应用领域：图像处理、计算机视觉、模式识别 核心目标：从图像中提取有意义信息，简化图像表示 预处理流程：传统方法常作为机器学习的预处理步骤 自动化特性：均可实现不同程度的自动化处理  区别   特性 阈值方法 ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/12/3D%20Res2Net%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--3D Res2Net的改造和使用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-12</div><div class="info-item-2">MM-UNet 论文学习笔记--3D Res2Net的改造和使用</div></div><div class="info-2"><div class="info-item-1">编码器细节：3D Res2Net的改造和使用核心思想我们选用了一个叫Res2Net的”高手”来做编码器，但它本来是处理2D普通照片的。我们通过一些巧妙的”改造”，让它能处理我们的3D医学图像，并且还让它继承了之前在普通照片上学到的”经验”。 为什么选择Res2Net？Res2Net的每个残差块内部都有分层式的残差连接，这让它能更有效地在粒度级别使用多尺度信息，扩展每一层的感受野。 就像工人同时拿着多种不同倍数的放大镜在工作：  一个小放大镜看细微的纹理和边缘（小尺度特征） 一个中倍放大镜看局部的结构（中尺度特征） 一个大倍放大镜看大致的轮廓（大尺度特征）  这对于边界模糊的前列腺图像来说，非常有用。 编码器的具体工作流程第一步：初始卷积（Convolution Stem）给定的图像首先通过一个卷积茎，它由并行的3×3×3卷积和1×1×1卷积组成，后面跟着求和操作。  3×3×3卷积：捕捉图像中小范围的、基本的局部特征（比如某个点是不是边缘） 1×1×1卷积：主要负责调整数据的通道数，为后续处理做准备 最后把两个结果相加，得到一个包含丰富基础信息的特征图  第二步：核心特征提取然后...</div></div></div></a><a class="pagination-related" href="/2025/11/12/A%20mixed%20Mamba%20U%E2%80%91net%20for%20prostate%20segmentation%20in%20MR%20images%20%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="MM-UNet 论文学习笔记--AFFM GCM MACM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-12</div><div class="info-item-2">MM-UNet 论文学习笔记--AFFM GCM MACM</div></div><div class="info-2"><div class="info-item-1">MM-UNet：3D前列腺MR图像分割方法核心目标：为什么要做这个研究？医生有一张前列腺的3D核磁共振（MR）图像，他们需要精确地知道图像中哪些像素是属于前列腺的。这个过程叫做”分割”。 手动分割的问题：非常耗时、费力，而且不同医生的判断可能会有差异。 自动分割的挑战：计算机来做这件事，面临三个主要难题：  图像质量差：MR图像背景杂乱（噪声多），前列腺边界模糊。 关系复杂：前列腺的形状和它周围的组织（膀胱、直肠等）是相互关联的，计算机需要理解整个图像的”上下文”才能准确判断边界。 数据特殊：3D的MR图像在上下、左右、前后三个方向的分辨率（清晰度）是不一样的。这导致传统的3D处理方法效果不好。  MM-UNET就是为了解决这三个挑战而设计的。 创新点一：自适应特征融合模块 (AFFM) – 解决”如何精准融合信息”1. 为什么需要它？在分割网络中，存在两种信息：  低级特征：来自网络的浅层，包含丰富的细节信息（如边缘、纹理），但也混有很多背景噪声。 高级特征：来自网络的深层，包含抽象的语义信息（知道”这是前列腺”），但缺乏细节，比较粗糙。  传统方法简单地把这两种特征拼接在一起...</div></div></div></a><a class="pagination-related" href="/2025/11/13/GCM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--GCM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-13</div><div class="info-item-2">MM-UNet 论文学习笔记--GCM</div></div><div class="info-2"><div class="info-item-1">Global Context-aware Module (GCM)概述GCM是一个用于医学图像分割的全局上下文理解模块，通过结合CNN的局部特征提取能力和Mamba的长序列建模能力，实现高效的全局上下文捕获。 1. GCM整体架构flowchart TD     A[输入特征图&lt;br&gt;B×C×H×W×D] --&gt; B[残差块1&lt;br&gt;Conv+IN+LeakyReLU]     B --&gt; C[残差块2&lt;br&gt;Conv+IN+LeakyReLU]     C --&gt; D[重塑序列&lt;br&gt;B×L×C&lt;br&gt;L=H×W×D]     D --&gt; E[Layer Normalization]     E --&gt; F[Mamba块]     F --&gt; G[重塑回空间结构&lt;br&gt;B×C×H×W×D]     G --&gt; H[输出特征图]          class A,B,C,D,E,F,G,H normal;          classDef normal fill:n...</div></div></div></a><a class="pagination-related" href="/2025/11/12/AFFM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-12</div><div class="info-item-2">MM-UNet 论文学习笔记--AFFM (自适应特征融合模块)</div></div><div class="info-2"><div class="info-item-1">AFFM (自适应特征融合模块) 学习笔记 🎯 解决的问题传统方法的缺陷：  直接将高层特征（轮廓信息）与低层特征（细节信息）拼接 导致背景噪声混入有用信息中 影响最终分割的精准度  🏗️ 模块设计思路AFFM就像一个智能的制图师，能够智能地融合两种不同类型的地图：  低层特征 &#x3D; “细节地图” ✅ 优点：包含丰富的边缘、纹理等细节信息 ❌ 缺点：混杂大量背景噪声，缺乏整体概念   高层特征 &#x3D; “轮廓地图” ✅ 优点：包含前列腺整体形状的语义信息 ❌ 缺点：缺乏精确定位的细节    🔄 三步骤工作流程第一步：特征对齐与拼接&#x2F;img&#x2F;屏幕截图 2025-11-12 215920.png 临时特征 &#x3D; 拼接(上采样(高层特征), 低层特征)  动作：将高层特征上采样到与低层特征相同尺寸 目的：让两种特征可以在同一尺度上进行融合  第二步：智能权重计算（核心创新）&#x2F;img&#x2F;屏幕截图 2025-11-12 220019.png 重要性权重 &#x3D; Sigmoid(全连接层2(全连接层1(全局平均池化(临时...</div></div></div></a><a class="pagination-related" href="/2025/11/13/MACM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--MACM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-13</div><div class="info-item-2">MM-UNet 论文学习笔记--MACM</div></div><div class="info-2"><div class="info-item-1">Multi-scale Anisotropic Convolution Module (MACM) 技术笔记模块概述核心目标MACM旨在解决3D医学图像分割中的三个关键挑战：  各向异性分辨率：适应不同方向的空间分辨率差异 多尺度特征需求：同时捕获局部细节和全局上下文 计算效率：在保持性能的同时控制计算复杂度  技术定位MACM是专门为3D医学图像设计的特征提取模块，通常集成在编码器路径中，用于增强特征的判别能力和空间感知。 整体架构模块组成graph TD     A[输入特征] --&gt; B[1×1×1卷积&lt;br&gt;通道调整]     B --&gt; C[并行ACB处理]          C --&gt; D[ACB k=3]     C --&gt; E[ACB k=7]      C --&gt; F[ACB k=13]     C --&gt; G[ACB k=15]          D --&gt; H[特征拼接]     E --&gt; H     F --&gt; H     G --&gt; H          H --&gt; I[残差...</div></div></div></a><a class="pagination-related" href="/2025/11/27/SENet/" title="Squeeze-and-Excitation Networks (SENet)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-27</div><div class="info-item-2">Squeeze-and-Excitation Networks (SENet)</div></div><div class="info-2"><div class="info-item-1">Squeeze-and-Excitation Networks (SENet)论文信息 论文标题: Squeeze-and-Excitation Networks 论文链接: https://arxiv.org/abs/1709.01507 官方代码: GitHub - hujie-frank&#x2F;SENet PyTorch实现: GitHub - miraclewkf&#x2F;SENet-PyTorch  一、SENet概述竞赛成绩SENet在ImageNet 2017竞赛图像分类任务中夺冠，取得突破性成果：  原最佳成绩: 2.991% (top-5 error) SENet成绩: 2.251% (top-5 error) 提升幅度: 0.74% 绝对提升  核心思想 研究动机: 显式建模特征通道间的相互依赖关系 技术策略: 采用”特征重标定”策略，避免引入新的空间维度 工作机制: 通过网络学习自动获取每个特征通道的重要程度 实现方式: 提升有用特征通道权重，抑制次要特征通道权重  架构特点 模块化设计: SE block作为子结构，可嵌入现有网络 端到端训练: 完全...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Soong</div><div class="author-info-description">有关机器学习，力扣代码训练等，欢迎探索</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Soong-A" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:926315593@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-CNN%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7%EF%BC%9A%E2%80%9D%E7%AE%A1%E4%B8%AD%E7%AA%A5%E8%B1%B9%E2%80%9D%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">🧩 CNN的局限性：”管中窥豹”问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%94%E5%96%BB%E8%A7%A3%E9%87%8A"><span class="toc-number">1.1.</span> <span class="toc-text">比喻解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E8%A1%A8%E7%8E%B0"><span class="toc-number">1.2.</span> <span class="toc-text">具体表现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">1.3.</span> <span class="toc-text">在实际应用中的影响</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%92%A5-Transformer%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7%EF%BC%9A%E2%80%9D%E5%85%A8%E5%91%98%E4%BC%9A%E8%AE%AE%E2%80%9D%E6%88%90%E6%9C%AC%E9%97%AE%E9%A2%98"><span class="toc-number">2.</span> <span class="toc-text">💥 Transformer的局限性：”全员会议”成本问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%94%E5%96%BB%E8%A7%A3%E9%87%8A-1"><span class="toc-number">2.1.</span> <span class="toc-text">比喻解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E8%A1%A8%E7%8E%B0-1"><span class="toc-number">2.2.</span> <span class="toc-text">具体表现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E5%85%B3%E7%B3%BB"><span class="toc-number">2.3.</span> <span class="toc-text">数学关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8A-%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94"><span class="toc-number">3.</span> <span class="toc-text">📊 两种模型对比</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/27/SENet/" title="Squeeze-and-Excitation Networks (SENet)">Squeeze-and-Excitation Networks (SENet)</a><time datetime="2025-11-27T08:22:00.000Z" title="发表于 2025-11-27 16:22:00">2025-11-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/26/DenseNet/" title="DenseNet论文学习笔">DenseNet论文学习笔</a><time datetime="2025-11-26T13:18:00.000Z" title="发表于 2025-11-26 21:18:00">2025-11-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/19/%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/" title="模型学习分类">模型学习分类</a><time datetime="2025-11-19T06:21:00.000Z" title="发表于 2025-11-19 14:21:00">2025-11-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/13/MACM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--MACM">MM-UNet 论文学习笔记--MACM</a><time datetime="2025-11-13T06:50:00.000Z" title="发表于 2025-11-13 14:50:00">2025-11-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/13/GCM%E5%B7%A5%E4%BD%9C%E7%BB%86%E8%8A%82/" title="MM-UNet 论文学习笔记--GCM">MM-UNet 论文学习笔记--GCM</a><time datetime="2025-11-13T05:30:00.000Z" title="发表于 2025-11-13 13:30:00">2025-11-13</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Soong</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>